{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "from nets import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([123, 117, 104]).reshape((1,1,1,3))\n",
    "shape = (227,227,3)\n",
    "\n",
    "checkpoints_dir = './checkpoints'\n",
    "CONTENT_IMG =  './images/Taipei1012.jpg'\n",
    "STYLE_IMG = './images/StarryNight2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_(images):\n",
    "    with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "        logits, endpoints = vgg.vgg_19(images,\n",
    "                                       num_classes=1000,\n",
    "                                       is_training=False,\n",
    "                                       spatial_squeeze=False)\n",
    "        return endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    image = tf.placeholder(tf.float32,shape=shape)\n",
    "    images  = tf.expand_dims(image, 0)\n",
    "    processed_images = image - MEAN_VALUES\n",
    "    image_endpoints = vgg_(processed_images)\n",
    "    \n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "        os.path.join(checkpoints_dir, 'vgg_19.ckpt'),\n",
    "        slim.get_model_variables('vgg_19'))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init_fn(sess)\n",
    "        content_img_ends = sess.run(image_endpoints , feed_dict={image: scipy.misc.imread(CONTENT_IMG)})\n",
    "        style_img_ends = sess.run(image_endpoints , feed_dict={image: scipy.misc.imread(STYLE_IMG)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_LAYERS = 'vgg_19/conv4/conv4_2'\n",
    "STYLE_LAYERS=[('vgg_19/conv1/conv1_1',1.),('vgg_19/conv2/conv2_1',1.5),('vgg_19/conv3/conv3_1',2.),\n",
    "              ('vgg_19/conv4/conv4_1',2.5),('vgg_19/conv5/conv5_1',3.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix_val(layer):\n",
    "    _ , height, weight, depth = layer.shape\n",
    "    area = height * weight\n",
    "    \n",
    "    x1 = layer.reshape(area,depth)\n",
    "    g = np.dot(x1.T, x1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix_tensor(layer):\n",
    "    shape = layer.get_shape().as_list()\n",
    "    area = shape[1] * shape[2]\n",
    "    depth = shape[3]\n",
    "    \n",
    "    x1 = tf.reshape(layer,(area,depth))\n",
    "    g = tf.matmul(tf.transpose(x1), x1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_style_loss(canvas , style):\n",
    "    style_loss = 0\n",
    "    for layer in STYLE_LAYERS:\n",
    "        layer_key , w = layer\n",
    "        layer_shape = style[layer_key].shape\n",
    "        A = gram_matrix_val(style[layer_key])\n",
    "        G = gram_matrix_tensor(canvas[layer_key])\n",
    "        M = layer_shape[1] * layer_shape[2]\n",
    "        N = layer_shape[3]\n",
    "        layer_loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A),2))\n",
    "        \n",
    "        style_loss = style_loss + w * layer_loss\n",
    "    \n",
    "    return style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_content_loss(canvas , content):\n",
    "    M = content.shape[1]*content.shape[2]\n",
    "    N = content.shape[3]\n",
    "    loss = (1./(2* N**0.5 * M**0.5 )) * tf.reduce_sum(tf.pow((canvas - content),2))  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_img = scipy.misc.imread(CONTENT_IMG).reshape((1,227,227,3)) - MEAN_VALUES\n",
    "nosie = np.random.uniform(-20,20,(1,227,227,3))\n",
    "init_canvas = 0.3*nosie + 0.7*content_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-8a75c06cbd94>:18 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "2.73779e+13\n",
      "1.89883e+11\n",
      "1.09599e+11\n",
      "8.19842e+10\n",
      "6.74809e+10\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    canvas = tf.Variable(init_canvas,dtype=tf.float32)\n",
    "    canvas_endpoints = vgg_(canvas)\n",
    "    \n",
    "    content_loss = build_content_loss(canvas_endpoints[CONTENT_LAYERS], \n",
    "                                      content_img_ends[CONTENT_LAYERS])\n",
    "    style_loss = build_style_loss(canvas_endpoints , style_img_ends)\n",
    "    total_loss = content_loss + 500 * style_loss\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(2)\n",
    "    train = optimizer.minimize(total_loss,var_list=[canvas])\n",
    "    \n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "        os.path.join(checkpoints_dir, 'vgg_19.ckpt'),\n",
    "        slim.get_model_variables('vgg_19'))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        init_fn(sess)\n",
    "        \n",
    "        for i in range(1001):\n",
    "            _ , total_loss_, canvas_ = sess.run([train , total_loss , canvas])\n",
    "            if i % 100 == 0:\n",
    "                print total_loss_\n",
    "                output_img = canvas_ + MEAN_VALUES\n",
    "                file_name = './results_%s.png' % i\n",
    "                scipy.misc.imsave(file_name, np.clip(output_img[0], 0, 255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
